{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1656502a",
   "metadata": {},
   "source": [
    "# Lab 9: Neural Network Initialization and Data Centering\n",
    "\n",
    "In this lab, you will explore two key concepts in neural network training:\n",
    "1. The effect of weight initialization on learning\n",
    "2. The impact of data centering on gradient descent\n",
    "\n",
    "### Learning Objectives\n",
    "- Understand how initializing all weights to the same value affects learning\n",
    "- Observe how non-centered data affects learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47f0ad2",
   "metadata": {},
   "source": [
    "### Step 1: Import Libraries\n",
    "To begin, import the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c6d78a",
   "metadata": {},
   "source": [
    "### Step 2: Generate Synthetic Data\n",
    "We will create a 2D dataset for binary classification with two configurations:\n",
    "1. **Centered Data**: The mean of the dataset is near the origin\n",
    "2. **Non-Centered Data**: The mean is shifted away from the origin\n",
    "\n",
    "Your Task:\n",
    "- Modify the function to shift the data when `centered=False`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic data\n",
    "def generate_data(n_samples=200, centered=True):\n",
    "    np.random.seed(0)\n",
    "    X = np.random.randn(n_samples, 2)\n",
    "    y = (X[:, 0] ** 2 + X[:, 1] ** 2 > 1).astype(int)\n",
    "    \n",
    "    # TODO: If centered is False, shift the data by adding a constant (e.g., 5)\n",
    "    \n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9cb413f",
   "metadata": {},
   "source": [
    "### Step 3: Simulate a Simple Neural Layer\n",
    "Here, we define a single layer with a specified number of neurons. Each neuron will learn a different feature.\n",
    "\n",
    "Your Tasks:\n",
    "- Implement weight initialization for two cases:\n",
    "  - **Same Initialization**: All weights are initialized to the same small value\n",
    "  - **Random Initialization**: Weights are initialized randomly within a range\n",
    "- Implement the `forward` method to compute the linear transformation of the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate a simple neural layer\n",
    "class SimpleLayer:\n",
    "    def __init__(self, input_dim, num_neurons, init=\"random\"):\n",
    "        self.num_neurons = num_neurons\n",
    "        if init == \"same\":\n",
    "            # TODO: Initialize all weights to the same small value (e.g., 0.1)\n",
    "            self.weights = ...\n",
    "        elif init == \"random\":\n",
    "            # TODO: Initialize weights randomly between -0.5 and 0.5\n",
    "            self.weights = ...\n",
    "        else:\n",
    "            raise ValueError(\"Invalid init type!\")\n",
    "\n",
    "    def forward(self, X):\n",
    "        # TODO: Perform a linear transformation of the input\n",
    "        return ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27069734",
   "metadata": {},
   "source": [
    "### Step 4: Visualization Helpers\n",
    "These functions help visualize:\n",
    "1. The features learned by neurons in the layer\n",
    "2. The gradient contours for centered and non-centered data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization helpers\n",
    "def plot_features(features, ax, title):\n",
    "    for i in range(features.shape[1]):\n",
    "        ax.plot(features[:, i], label=f\"Neuron {i+1}\")\n",
    "    ax.set_title(title)\n",
    "    ax.legend()\n",
    "\n",
    "def plot_gradient_contours(X, y, ax, title):\n",
    "    xx, yy = np.meshgrid(np.linspace(-3, 8, 100), np.linspace(-3, 8, 100))\n",
    "    grad_magnitude = np.sqrt(xx**2 + yy**2) \n",
    "    ax.contourf(xx, yy, grad_magnitude, levels=20, cmap=\"coolwarm\")\n",
    "    ax.scatter(X[:, 0], X[:, 1], c=y, cmap=\"coolwarm\", edgecolor=\"k\")\n",
    "    ax.set_title(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7759c5",
   "metadata": {},
   "source": [
    "### Step 5: Analyze and Visualize\n",
    "Now, you will:\n",
    "1. Generate datasets (centered and non-centered).\n",
    "2. Create two neural layers:\n",
    "   - One with all weights initialized to the same value\n",
    "   - One with weights initialized randomly\n",
    "3. Pass the data through these layers and visualize:\n",
    "   - Features learned by the neurons\n",
    "   - Gradient contours for centered vs. non-centered data\n",
    "\n",
    "Your Tasks:\n",
    "- Complete the TODOs to implement each step\n",
    "- Observe and compare the visualizations\n",
    "- In the markdown cell at the bottom, write down your analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Generate centered and non-centered data\n",
    "X_centered, y = ...\n",
    "X_uncentered, _ = ...\n",
    "\n",
    "\n",
    "# TODO: Initialize two layers, one with same weights and one with random weights\n",
    "layer_same = ...\n",
    "layer_random = ...\n",
    "\n",
    "# TODO: Forward pass through the layers\n",
    "features_same = ...\n",
    "features_random = ...\n",
    "\n",
    "# Plot the features\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "plot_features(features_same, axes[0, 0], \"Features with Same Initialization\")\n",
    "plot_features(features_random, axes[0, 1], \"Features with Random Initialization\")\n",
    "\n",
    "# Gradient visualization (centered vs. uncentered data)\n",
    "plot_gradient_contours(X_centered, y, axes[1, 0], \"Centered Data Gradients\")\n",
    "plot_gradient_contours(X_uncentered, y, axes[1, 1], \"Uncentered Data Gradients\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analysis:** \n",
    "\n",
    "- Effect of weight initialization on learning: ...\n",
    "- Impact of data centering on gradient descent: ... "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
